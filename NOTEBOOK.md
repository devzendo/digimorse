# Digimorse Lab Notebook

<!-- Edited with Typora.io, to allow and render MathJax -->

This notebook was started nearly 2 years after I started the project, and has been backfilled to the point where I started getting bogged down due to mathematical difficulties, developing the channel codec, specifically, implementing the Low-Density Parity-Check code.

It is intended to document approaches / hypotheses, and experimental results.

For an overview of the project as a whole, see "The digimorse Communications Protocol" in the *docs* directory.

## 1 July 2022

Starting to work on the design of the channel encoder.

Block size of the source encoder output is 112 bits. See *src/libs/channel_codec/channel_encoder.rs* for details.

Decided to use the same 14-bit polynomial CRC as in FT8 (0x2757); it isn't critical since output of the LDPC would either be a valid codeword or a decode failure.



## 16 July 2022

112 bits of source encoder output plus 14 bits of CRC yields a 126 bit message as input to the LDPC. I chose a (240, 126) LDPC...



## 11 August 2022

Using the *ldpc* crate by Maxime Tremblay. Study greatly aided by Prof. Sarah Johnson's *Iterative Error Correction* book.

This crate provides decoders; encoding would be done by matrix multiplication of the message vector by the generator matrix. It also provides a 'sampling' method of constructing the LinearCode, and command-line tools to generate a pair of matrices. I couldn't get this working.



## 18 August 2022

I switched to using Daniel Estévez's *ldpc-toolbox* crate to create the parity check matrix.

`ldpc-toolbox mackay-neal 126 240 6 3 0 --uniform --min-girth 8 --girth-trials 10000 --search`

This found a seed of 512, and its output is in *parity_check_matrix.alist*. Need to convert this alist format into Rust code that'll construct a SparseBinMat (as used in Maxime Tremblay's *ldpc* crate), that'll be compiled statically. *ldpc-toolbox* uses a SparseMatrix, so I wrote a converter from this to SparseBinMat.

## 23 August 2022

Generating Rust code for the statically-compiled parity check matrix. The matrix is created using *ldpc-toolbox*, as an *alist* file, read in as a SparseMatrix, converted to a SparseBinMat, and rust code generated from that that re-instantiates the SparseBinMat as *lazy_static* LinearCode.

## 4 September 2022

Changed the codeword size to 252 bits. I had chosen $w_{c}=3$ and $w_{r}=6$ (Radford M. Neal's LDPC generator allows choice of $w_{c}$ but doubles this to provide $w_{r}$.), with $k=126$ as the output from the source encoder.  However I realised that for a regular LDPC there is a constraint on the number of 1s in the parity-check matrix $H$ such that $Mw_{r} = Nw_{c}$ where M is the redundancy and N the codeword length. Initially I chose dimensions that did not honour this constraint. I subsequently chose $k=126$ and doubled this for the codeword size $k=252$, giving a rate of ${1 \over 2}$. Also, 252 is divisible by 3 and so can be partitioned into groups of 3 bits. Therefore digimorse uses a (252,126) LDPC, giving 126 bits of redundant parity information.

Generated a new parity check matrix of this dimension. Switched to using Radford M. Neal's LDPC-Codes project to create this (as a 'pchk' file), converting it to an 'alist' file, then using my existing rust generator... at this stage I was thinking I could interoperate between LDPC-Codes and *ldpc-toolbox*.

Oddly, I seemed to need to transpose the pchk file... and the dimensions of the generator matrix (generated by the LinearCode constructor of Maxime Tremblay's *ldpc*) were the wrong way round...



Using Maxime Tremblay's bit-flipping decoder (or his belief propagation decoder), a round trip, encoding / decoding a message with no noise generates a single bit difference. 

I'm assuming that after a decode, the resulting codeword contains the decoded message in the right-hand half of the codeword.

This assumption may well be incorrect. I think this clean demarcation between parity and message data in the codeword would only apply if the generator matrix is systematic (Johnson, p41) - ie the generator matrix contains the $K \times K$ *identity matrix* $I_K$ as its first $K$ columns.



## 5 September 2022

Thinking that there may be a bug in the bit-flipping decoder - whose code I couldn't quite match up with that in (Johnson), I started implementing my own version, closely following the book.



## 13 September 2022

Implemented ColumnAccess for SparseBinMat - it's optimised for row-based access. Maybe a PR?



## 20 September 2022

My bit-flipping decoder gives precisely the same results as the *ldpc* crate's version. So we're either both wrong or there's something else amiss - presumably my assumption (4 Sept 2022) that the decoded codeword can be neatly split into parity and decoded message along the left-right half border.

Tried inverting the parity check matrix in Jupyter, but it's not invertible (can't recall justification for attempting this now). Tried multiplying a decoded codeword with the parity check matrix, but this yields zeroes. 

To get the decoded message out of the decoded codeword, multiply the decoded codeword by the parity check matrix. This was not obvious to me; not mentioned in "Iterative Error Correction" or other introductions; It was however made clear in (p.28 of https://core.ac.uk/download/pdf/37320505.pdf An LDPC Error Control Strategy for Low Earth Orbit Satellite Communication Link Applications by F.J. Olivier )





## 28 September 2022

The alist format used by Radford Neal's *LDPC-Codes* tools is different to that used by Daniel Estévez's *ldpc-toolbox* crate. Radford's variant format has *rows columns* as its first line; Daniel's has it the other way round. The misreading of files was why I needed to transpose the parity check matrix. Wrote my own reader that is compatible with Radford's format. Not surprised that there are different variants - the "spec" of the alist format (http://www.inference.org.uk/mackay/codes/alist.html) describes the size of the matrix as $N$ and $M$ - hardly descriptive. I pored over Radford's C code to build my reader.



## 16 October 2022

I had been loading the parity check matrix into the *ldpc* crate's LinearCode constructor, which will create an appropriate generator matrix on construction. This can then be used when encoding by matrix multiplication. However I couldn't find a way to determine which bits of the decoded codeword form the message. 

Decided to try using Radford Neal's tools to pre-create the generator matrix. An advantage of this is that in addition to describing the generator matrix, the output of the *make-gen* tool shows the column order list as well. 

Generated using:

```
make-gen parity_check_matrix.pchk generator_matrix.gen dense
print-gen generator_matrix.gen > generator_matrix.txt
```

This matrix is $(126, 126)$, where "The first $K$ columns of the $K$ by $N$ generator matrix will then be the identity matrix." (LDPC-Codes/encoding.html). The .gen file does NOT contain $I$. I have tried added an identity matrix to this - on the left and the right of the generator matrix, and with the original generated matrix as-is, and transposed. Using the two-matrix form of the LinearCode constructor that takes a parity check and a generator matrix.

However, the LinearCode fails to construct using these two matrices, since they are not orthogonal - their dot product is not zero. Why?



## 10 November 2022

Started writing these notes as a way of working out how I'd become stuck.

Current attempt is to use Radford Neal's LDPC-Codes tools to generate the generator matrix from the parity check matrix, then generate Rust code for these, and construct the LinearCode from them.

This doesn't construct, since the two matrices are not orthogonal.

Also, using his encode/decode tools is unsuccessful, saying something to the effect that codewords over 32 bits are absurd (perhaps his implementation is only effective for those small lengths?)

The list of information-carrying columns reported by the `make-gen` and `print-gen` tool shows that there's not a contiguous range of columns on the right-hand side: as observed (16 Oct 2022) the generated matrix does not contain $I$. 



Unsure how to proceed; re-read (Johnson p42), which states: 

"In general, a generator matrix for a code with parity-check matrix $H$ can be found by performing Gauss-Jordan elimination on $H$ to obtain it in the form

$H = [A \space \space \space \space I_{N-K}]$.

where $A$ is an $(N - K) \times K$ binary matrix and $I_{N - K}$ is the identity matrix of order $N - K$. The generator matrix is then

$G = [I_K \space \space \space A^T]$."

$H$ is then put into *row-echelon form* by applying elementary row operations in $GF(2)$. Then it's put into *reduced row-echelon form* so that any column that contains a leading 1 has 0s everywhere else. It's then put into standard form, where the last $m$ columns are the $m $ columns that contain the leading 1s - ie there's an identity matrix at the right hand side.

Assumption: *starting with a 'good' parity check matrix, after these transforms there will be an identity matrix at the RHS*. Is this precisely the same as being in standard reduced row-echelon form? Might there be a staggered mostly-diagonal? Is that OK? How do you know which the message bits are in a decoded codeword, from that?

I loaded the parity check matrix into *sagemath*, and use the following to obtain its reduced row-echelon form:

```
sage: H = matrix(GF(2), [
[0, 0, 0, 0, 0, 0,...... ],
.....
.........]
])
sage: print(H.rref())
```

This yields a matrix that has *almost* an identity matrix at its LHS. There are 7 rows below the last point on the diagonal, that don't form part of it.

## 11 November 2022

This experiment started with a parity check matrix generated using *LDPC-Codes*; perhaps there's some aspect of the matrix that doesn't yield an identity matrix, after conversion to reduced-row-echelon form/ standard form. 

*Question: What are the qualities that would lead to that?*

Re-state my requirements - I need a sparse parity check matrix in $GF(2)$ that is:

* Of order (126, 252)
* Regular, with 3 1s per column and 6 1s per row
* No 4-cycles, that is, there is no pair of columns that have 1s in the same two row-positions
* Convertible to a generator matrix by placing in row-echelon form, then reduced row-echelon form, then standard form, such that there is an identity matrix at the RHS, and that is orthogonal to the original parity check matrix



### Possible ways forward

* A. Write my own parity matrix generator - MacKay Neal method? Would make experimentation easier, less conversion between alist and SparseBinMat etc.

* B. Look again at *ldpc* method of generating parity check matrix - RandomRegularCode. Would have to write persistence code for this - to generate a random code, test its efficacy then generate rust for it, if OK. *But how to know which bits are the message bits in a decoded codeword?*

* C. Investigate *labrador-ldpc*. Looks like the message size would have to increase to 128 bits (no biggie). Benefit of this is that the matrices are already generated, and since this has been extensively used/peer reviewed, will work. The matrices in this LDPC are systematic, so the message bits in the decoded codeword are known and can be easily extracted. It would mean scrapping all current work so far, but that's OK - it's got to *work*, that's the primary objective here!

* D. Investigate LDPC code in other languages.

* E. Give up the idea of using error correction - recent Practical Wireless article describes how EC was added to PSK31, but that it isn't the mode-variant that became the most used. This would mean losing the coding gain, which is impressive for LDPC. It would also halve the modulation / transmission time, making the mode better, interactively - reducing the round-trip time for a QSO, which is something that will put CW aficionados off. Sunk cost fallacy? It may be possible to add a UI flag to control whether EC is used, or not, and have metrics to see whether it's popular.

* F. Use some other error correction scheme that's easier to work with, has a lower coding gain but reduces the amount of error correction information that's transmitted.

  

Point to note: TRIZ has a creative trigger where you imagine the feature done, and move beyond your stuckness; you see the problem in the rear-view mirror, and this can lead to insights.

Considering C, and E (optional error correction). 



## 12 November 2022

Started using the *labrador-ldpc* crate, which solves all my problems! I've added two extra (currently spare) bits to the packed message format:

* 112 bits of source encoded data
* 2 spare bits
* 14 bits of CRC

This is then encoded with the 256 bit codeword variant 'TC256', giving 128 bits of parity check data.



## 13 November 2022

LDPC encoder now works. Now need to flesh out the channel encoder. It'll be an active object that takes a SourceEncoding (binary data + end flag), and produces a ChannelEncoding (binary data + end flag). It will do the following transforms:

* Adding the LDPC
* Shuffling the bytes/nybbles of the data+unused+crc+ldpc to mitigate burst errors - this needs quantifying, is it necessary? Research required.
* Mapping the data through a Gray code. Research required.
* Emitting:
  * Ramp up
  * Costas array tone symbols
  * Data tone symbols
  * Costas array tone symbols
  * Ramp down

Next: Burst error mitigation

After that: Gray code research

After that: Costas array research



## 5 December 2022

Outstanding: Burst error mitigation

Currently: Gray code research

After that: Costas array research



Gray code - is this still patented? No, it was granted in 1953 and expired in 1970 - see https://patents.google.com/patent/US2632058?oq=US+2632058+A



Makes the transmission less susceptible to noise; nybbles assigned to different tones differ in only one position, improving decode performance where Doppler spread of the incoming frequencies is near the tone separation.



## 6 December 2022

Done the Gray coding; now onto Costas Array research.

FT8 uses a 7x7 array with one of its 8 tones unused to modulate the array.

## 8 December 2022

Possible tasks today:

* More Costas array research
* Investigate the playback DDS odd frequency anomalies
* Start the Transceiver subsystem

### Costas array research

Why does FT8 use a 7 x 7 array [3, 1, 4, 0, 6, 5, 2], when there are 8 tones? Using an 8 x 8 array would 'fit better'  but use one more time period.. is 7 x 7 sufficient to synchronise (certainly seems to!). Could the 7 x 7 array of FT8 be used, modulated using tones 0-6 of digimorse's 0-15?

I've asked Mike Hasselbeck WB2FKO, who presented on FT8's use of Costas arrays, after reversing their use from the Fortran FT8 code, and asking questions of the developers. In his presentation of his research at https://www.youtube.com/watch?v=rjLhTN59Bg4, Phil Karn KA9Q asked Mike whether so much data needs to be devoted to synch.

Phil: "the whole point of all this [synch] is to tell the decoder to go ahead and decode.. the data part of the packet... sometimes I wonder if it's really necessary - some of the [systems] I've devised, I don't put in any synchronisation at all, just try all possible offsets until something falls out"

Mike speculates that the Costas array could be used to prevent decodes by other implementations.

I think I _do_ need synchronisation, in order to allocate decoders at the appropriate part of the FFT data. If these decoders don't detect a valid array, or if they do but then fail to decode a codeword, or if they do decode a codeword but its CRC doesn't match, then they won't emit the source encoding to the playback. The array is the first line of defence.

But how to reliably build up an incoming array? How to place a newly-initialised decoder at a frequency? Iterate over all positions where there's no current decoder, and if there's a tone 3 (say, if using the FT8 array), allocate and let that decoder have all subsequent tones at that frequency? Destroy the decoder after array recording if the synch signal is weaker than the baseline (midway point in the sorted synch signal strength array). Signals stronger than this are candidates for further decoding.

Once the n tones of the array have been received, the $\Delta f$ and $\Delta t$ can be searched for, and these used in more precisely locating the rest of the frame's tones.

Outstanding: Costas array size

### Playback sine wave distortion

Changing to a f32 for the sine table did not resolve the problem; the resulting tone was a little less harsh, but the distortion - especially noticeable in the test that increases the playback frequency, around 740 Hz - was still present. Reviewed the DDS code, and can't see anything obviously wrong.

Wondering about either adding a digital low pass filter after the summing of the tone sine values, or converting from DDS to a sine table per output tone, generated on frequency change. Frequency change doesn't happen per-tone, it's just a nice-to-have when adjusting the sidetone, or if slewing the playback tone from its audio offset to a known sidetone (a possible aid when selecting a single decoder to play back).

## 9 December 2022

Adding the digital low pass filter didn't make any difference - and didn't appear to be filtering anything. Removed it. Still need to find a better way to generate tones for Morse playback.

Looked at how to generate the Gaussian Frequency Shift Keying output for the channel-encoded symbols. Much to understand about the filter, but a good implementation is Karlis Goba's ft8_lib at https://github.com/kgoba/ft8_lib. gen_ft8.c has GFSK waveform generation code that goes from the list of symbols to a waveform. I was thinking of computing this iteratively in the audio generator, but might just convert en masse in a similar style. I wonder whether there may be a bug in the insertion of the first and last ramp up/down symbols?

I looked at WSJT-X's Modulator.cpp but there are many things going on in the same area of code that make it very hard to extricate the actual GFSK modulation; variable names are obscure, and there are very few comments (except //??? which is most helpful).

Outstanding: Playback sine wave distortion

 
